"""
Influencer Finder v1.0
KOLå‘ç°å¼•æ“ â€” ç²¾å‡†æŒ–æ˜å‚ç±»å½±å“è€… + äº’åŠ¨è´¨é‡è¯„åˆ† + åˆä½œä»·å€¼è¯„ä¼°

Features:
- NicheScorer: åŸºäºå…³é”®è¯/è¯é¢˜ç›¸å…³åº¦è¯„åˆ†
- EngagementQuality: åŒºåˆ†çœŸäº’åŠ¨ vs æ°´å†›äº’åŠ¨
- GrowthTracker: ç²‰ä¸å¢é•¿è½¨è¿¹åˆ†æ
- InfluencerRanker: å¤šç»´åŠ æƒç»¼åˆæ’å
- CooperationEstimator: åˆä½œROIé¢„ä¼°
- WatchList: æŒä¹…åŒ–å…³æ³¨åˆ—è¡¨ + å˜åŠ¨è¿½è¸ª
"""

import json
import logging
import math
import sqlite3
import threading
from collections import defaultdict
from dataclasses import dataclass, field, asdict
from datetime import datetime, timezone, timedelta
from enum import Enum
from typing import Dict, List, Optional, Tuple, Set

logger = logging.getLogger(__name__)


# â”€â”€ æ•°æ®æ¨¡å‹ â”€â”€


class InfluencerTier(Enum):
    """å½±å“è€…ç­‰çº§"""
    NANO = "nano"           # 1K-10K
    MICRO = "micro"         # 10K-50K
    MID = "mid"             # 50K-500K
    MACRO = "macro"         # 500K-1M
    MEGA = "mega"           # 1M+

    @classmethod
    def from_followers(cls, count: int) -> "InfluencerTier":
        if count < 10_000:
            return cls.NANO
        elif count < 50_000:
            return cls.MICRO
        elif count < 500_000:
            return cls.MID
        elif count < 1_000_000:
            return cls.MACRO
        return cls.MEGA


@dataclass
class InfluencerProfile:
    """å½±å“è€…ç”»åƒ"""
    user_id: str
    username: str
    display_name: str = ""
    bio: str = ""
    followers: int = 0
    following: int = 0
    tweet_count: int = 0
    verified: bool = False
    created_at: Optional[str] = None

    # è®¡ç®—æŒ‡æ ‡
    tier: str = ""
    niche_score: float = 0.0
    engagement_score: float = 0.0
    quality_score: float = 0.0
    growth_score: float = 0.0
    overall_score: float = 0.0
    cooperation_value: float = 0.0

    # å…ƒæ•°æ®
    discovered_at: str = ""
    last_updated: str = ""
    tags: List[str] = field(default_factory=list)
    notes: str = ""

    def to_dict(self) -> Dict:
        return asdict(self)

    @classmethod
    def from_dict(cls, d: Dict) -> "InfluencerProfile":
        known = {f.name for f in cls.__dataclass_fields__.values()}
        filtered = {k: v for k, v in d.items() if k in known}
        return cls(**filtered)


@dataclass
class EngagementSample:
    """äº’åŠ¨æ ·æœ¬"""
    tweet_id: str
    likes: int = 0
    retweets: int = 0
    replies: int = 0
    quotes: int = 0
    impressions: int = 0
    created_at: str = ""

    @property
    def total_engagement(self) -> int:
        return self.likes + self.retweets + self.replies + self.quotes

    @property
    def engagement_rate(self) -> float:
        if self.impressions > 0:
            return self.total_engagement / self.impressions
        return 0.0


@dataclass
class NicheConfig:
    """å‚ç±»é…ç½®"""
    name: str
    keywords: List[str] = field(default_factory=list)
    hashtags: List[str] = field(default_factory=list)
    seed_accounts: List[str] = field(default_factory=list)
    min_followers: int = 1000
    max_followers: int = 10_000_000
    min_engagement_rate: float = 0.01
    language: str = "en"

    def to_dict(self) -> Dict:
        return asdict(self)


# â”€â”€ Nicheç›¸å…³åº¦è¯„åˆ† â”€â”€


class NicheScorer:
    """å‚ç±»ç›¸å…³åº¦è¯„åˆ†å™¨"""

    def __init__(self, config: NicheConfig):
        self.config = config
        self._keywords_lower = [k.lower() for k in config.keywords]
        self._hashtags_lower = [h.lower().lstrip("#") for h in config.hashtags]

    def score_bio(self, bio: str) -> float:
        """Bioç›¸å…³åº¦è¯„åˆ† (0-1)"""
        if not bio:
            return 0.0
        bio_lower = bio.lower()
        hits = sum(1 for kw in self._keywords_lower if kw in bio_lower)
        tag_hits = sum(1 for tag in self._hashtags_lower if tag in bio_lower)
        total = hits + tag_hits
        max_possible = len(self._keywords_lower) + len(self._hashtags_lower)
        if max_possible == 0:
            return 0.0
        # å¯¹æ•°è¡°å‡ï¼Œé¿å…å †ç Œå…³é”®è¯å¾—é«˜åˆ†
        return min(1.0, math.log1p(total) / math.log1p(max_possible))

    def score_tweets(self, tweets: List[Dict]) -> float:
        """æ¨æ–‡å†…å®¹ç›¸å…³åº¦è¯„åˆ† (0-1)"""
        if not tweets:
            return 0.0
        relevant = 0
        for tweet in tweets:
            text = tweet.get("text", "").lower()
            if any(kw in text for kw in self._keywords_lower):
                relevant += 1
            elif any(tag in text for tag in self._hashtags_lower):
                relevant += 1
        return min(1.0, relevant / len(tweets))

    def score(self, profile: InfluencerProfile, tweets: List[Dict] = None) -> float:
        """ç»¼åˆNicheè¯„åˆ†"""
        bio_score = self.score_bio(profile.bio)
        tweet_score = self.score_tweets(tweets or [])
        # Bioæƒé‡0.4, æ¨æ–‡å†…å®¹0.6
        return bio_score * 0.4 + tweet_score * 0.6


# â”€â”€ äº’åŠ¨è´¨é‡è¯„ä¼° â”€â”€


class EngagementQualityAnalyzer:
    """äº’åŠ¨è´¨é‡åˆ†æå™¨ â€” åŒºåˆ†çœŸäº’åŠ¨å’Œæ°´å†›"""

    def __init__(self):
        self.suspicious_thresholds = {
            "like_reply_ratio_max": 100,  # ç‚¹èµ/å›å¤ > 100 å¯ç–‘
            "retweet_reply_ratio_max": 50,  # è½¬æ¨/å›å¤ > 50 å¯ç–‘
            "zero_reply_pct_max": 0.9,    # 90%ä»¥ä¸Šæ¨æ–‡0å›å¤å¯ç–‘
            "engagement_cv_min": 0.3,      # äº’åŠ¨é‡å˜å¼‚ç³»æ•°è¿‡ä½(å¤ªå‡åŒ€)å¯ç–‘
        }

    def analyze(self, samples: List[EngagementSample]) -> Dict:
        """åˆ†æäº’åŠ¨è´¨é‡"""
        if not samples:
            return {"quality_score": 0.0, "flags": ["no_samples"], "details": {}}

        flags = []
        details = {}

        # 1. ç‚¹èµ/å›å¤æ¯”
        total_likes = sum(s.likes for s in samples)
        total_replies = sum(s.replies for s in samples)
        if total_replies > 0:
            lr_ratio = total_likes / total_replies
            details["like_reply_ratio"] = round(lr_ratio, 1)
            if lr_ratio > self.suspicious_thresholds["like_reply_ratio_max"]:
                flags.append("suspicious_like_ratio")
        elif total_likes > 0:
            flags.append("zero_replies_with_likes")
            details["like_reply_ratio"] = float("inf")

        # 2. è½¬æ¨/å›å¤æ¯”
        total_rt = sum(s.retweets for s in samples)
        if total_replies > 0:
            rr_ratio = total_rt / total_replies
            details["retweet_reply_ratio"] = round(rr_ratio, 1)
            if rr_ratio > self.suspicious_thresholds["retweet_reply_ratio_max"]:
                flags.append("suspicious_retweet_ratio")

        # 3. é›¶å›å¤æ¨æ–‡å æ¯”
        zero_reply = sum(1 for s in samples if s.replies == 0)
        zero_pct = zero_reply / len(samples)
        details["zero_reply_pct"] = round(zero_pct, 2)
        if zero_pct > self.suspicious_thresholds["zero_reply_pct_max"]:
            flags.append("mostly_zero_replies")

        # 4. äº’åŠ¨é‡å˜å¼‚ç³»æ•°(CV)
        engagements = [s.total_engagement for s in samples]
        if engagements:
            mean = sum(engagements) / len(engagements)
            if mean > 0:
                variance = sum((e - mean) ** 2 for e in engagements) / len(engagements)
                cv = math.sqrt(variance) / mean
                details["engagement_cv"] = round(cv, 3)
                if cv < self.suspicious_thresholds["engagement_cv_min"]:
                    flags.append("too_uniform_engagement")

        # 5. äº’åŠ¨ç‡åˆ†å¸ƒ
        rates = [s.engagement_rate for s in samples if s.impressions > 0]
        if rates:
            avg_rate = sum(rates) / len(rates)
            details["avg_engagement_rate"] = round(avg_rate, 4)
        else:
            avg_rate = 0.0
            if engagements:
                # ä¼°ç®—: å‡è®¾å°è±¡ = ç²‰ä¸ * 0.1
                avg_rate = mean / 10000 if mean > 0 else 0.0
                details["estimated_engagement_rate"] = round(avg_rate, 4)

        # è´¨é‡è¯„åˆ†
        penalty = len(flags) * 0.15
        base_score = 1.0
        # æœ‰å›å¤æ˜¯å¥½ä¿¡å·
        reply_bonus = min(0.2, (total_replies / max(1, len(samples))) * 0.01)
        quality_score = max(0.0, min(1.0, base_score - penalty + reply_bonus))

        return {
            "quality_score": round(quality_score, 3),
            "flags": flags,
            "details": details,
        }


# â”€â”€ å¢é•¿è½¨è¿¹åˆ†æ â”€â”€


class GrowthTracker:
    """ç²‰ä¸å¢é•¿è½¨è¿¹åˆ†æ"""

    def __init__(self, db_path: str = "influencer_growth.db"):
        self.db_path = db_path
        self._local = threading.local()
        self._init_db()

    def _get_conn(self) -> sqlite3.Connection:
        if not hasattr(self._local, "conn") or self._local.conn is None:
            self._local.conn = sqlite3.connect(self.db_path)
            self._local.conn.row_factory = sqlite3.Row
            self._local.conn.execute("PRAGMA journal_mode=WAL")
        return self._local.conn

    def _init_db(self):
        conn = self._get_conn()
        conn.executescript("""
            CREATE TABLE IF NOT EXISTS growth_snapshots (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT NOT NULL,
                followers INTEGER NOT NULL,
                following INTEGER NOT NULL,
                tweet_count INTEGER NOT NULL DEFAULT 0,
                recorded_at TEXT NOT NULL DEFAULT (datetime('now')),
                UNIQUE(user_id, recorded_at)
            );
            CREATE INDEX IF NOT EXISTS idx_growth_user ON growth_snapshots(user_id);
            CREATE INDEX IF NOT EXISTS idx_growth_time ON growth_snapshots(recorded_at);
        """)
        conn.commit()

    def record(self, user_id: str, followers: int, following: int, tweet_count: int = 0):
        """è®°å½•ç²‰ä¸æ•°å¿«ç…§"""
        conn = self._get_conn()
        now = datetime.now(timezone.utc).isoformat()
        try:
            conn.execute(
                "INSERT OR REPLACE INTO growth_snapshots(user_id, followers, following, tweet_count, recorded_at) VALUES(?,?,?,?,?)",
                (user_id, followers, following, tweet_count, now),
            )
            conn.commit()
        except sqlite3.Error as e:
            logger.error("Growth record failed for %s: %s", user_id, e)

    def get_history(self, user_id: str, days: int = 30) -> List[Dict]:
        """è·å–ç²‰ä¸å†å²"""
        conn = self._get_conn()
        cutoff = (datetime.now(timezone.utc) - timedelta(days=days)).isoformat()
        rows = conn.execute(
            "SELECT followers, following, tweet_count, recorded_at FROM growth_snapshots WHERE user_id=? AND recorded_at>=? ORDER BY recorded_at",
            (user_id, cutoff),
        ).fetchall()
        return [dict(r) for r in rows]

    def calculate_growth(self, user_id: str, days: int = 30) -> Dict:
        """è®¡ç®—å¢é•¿æŒ‡æ ‡"""
        history = self.get_history(user_id, days)
        if len(history) < 2:
            return {
                "growth_rate": 0.0,
                "daily_avg": 0.0,
                "trend": "insufficient_data",
                "data_points": len(history),
            }

        first = history[0]["followers"]
        last = history[-1]["followers"]
        diff = last - first

        # è®¡ç®—æ—¥å‡å¢é•¿
        try:
            t0 = datetime.fromisoformat(history[0]["recorded_at"])
            t1 = datetime.fromisoformat(history[-1]["recorded_at"])
            span_days = max(1, (t1 - t0).days)
        except (ValueError, TypeError):
            span_days = max(1, days)

        daily_avg = diff / span_days
        growth_rate = diff / max(1, first)

        # è¶‹åŠ¿åˆ¤å®š
        if len(history) >= 5:
            mid = len(history) // 2
            first_half_avg = sum(h["followers"] for h in history[:mid]) / mid
            second_half_avg = sum(h["followers"] for h in history[mid:]) / (len(history) - mid)
            if second_half_avg > first_half_avg * 1.05:
                trend = "accelerating"
            elif second_half_avg < first_half_avg * 0.95:
                trend = "decelerating"
            else:
                trend = "steady"
        else:
            trend = "growing" if diff > 0 else ("declining" if diff < 0 else "flat")

        return {
            "growth_rate": round(growth_rate, 4),
            "daily_avg": round(daily_avg, 1),
            "absolute_change": diff,
            "trend": trend,
            "data_points": len(history),
            "period_days": span_days,
        }

    def growth_score(self, user_id: str, days: int = 30) -> float:
        """å¢é•¿è¯„åˆ† (0-1)"""
        metrics = self.calculate_growth(user_id, days)
        if metrics["trend"] == "insufficient_data":
            return 0.5  # ä¸­æ€§

        rate = metrics["growth_rate"]
        # sigmoidæ˜ å°„: 30å¤©å¢é•¿10%=0.73, 50%=0.95
        score = 1 / (1 + math.exp(-10 * rate))
        # è¶‹åŠ¿åŠ æˆ
        trend_bonus = {
            "accelerating": 0.1,
            "growing": 0.05,
            "steady": 0,
            "decelerating": -0.05,
            "declining": -0.1,
            "flat": 0,
        }
        score = max(0.0, min(1.0, score + trend_bonus.get(metrics["trend"], 0)))
        return round(score, 3)


# â”€â”€ åˆä½œä»·å€¼è¯„ä¼° â”€â”€


class CooperationEstimator:
    """åˆä½œä»·å€¼è¯„ä¼°å™¨"""

    # CPEåŸºå‡† (æ¯äº’åŠ¨æˆæœ¬, USD)
    CPE_BENCHMARKS = {
        InfluencerTier.NANO: (0.05, 0.15),
        InfluencerTier.MICRO: (0.10, 0.30),
        InfluencerTier.MID: (0.20, 0.60),
        InfluencerTier.MACRO: (0.50, 1.50),
        InfluencerTier.MEGA: (1.00, 3.00),
    }

    # é¢„ä¼°æŠ¥ä»·åŸºå‡† (USD/æ¨æ–‡)
    RATE_BENCHMARKS = {
        InfluencerTier.NANO: (10, 100),
        InfluencerTier.MICRO: (100, 500),
        InfluencerTier.MID: (500, 5000),
        InfluencerTier.MACRO: (5000, 20000),
        InfluencerTier.MEGA: (20000, 100000),
    }

    def estimate(
        self,
        profile: InfluencerProfile,
        avg_engagement: float = 0.0,
        niche_score: float = 0.0,
    ) -> Dict:
        """è¯„ä¼°åˆä½œä»·å€¼"""
        tier = InfluencerTier.from_followers(profile.followers)
        cpe_range = self.CPE_BENCHMARKS.get(tier, (0.1, 0.5))
        rate_range = self.RATE_BENCHMARKS.get(tier, (50, 500))

        # é¢„ä¼°æŠ¥ä»·
        est_rate = (rate_range[0] + rate_range[1]) / 2

        # é¢„ä¼°CPE
        est_cpe = (cpe_range[0] + cpe_range[1]) / 2

        # é¢„ä¼°äº’åŠ¨æ•°
        if avg_engagement > 0:
            est_engagements = avg_engagement
        else:
            # ç”¨ç²‰ä¸æ•° * é»˜è®¤äº’åŠ¨ç‡ä¼°ç®—
            default_rates = {
                InfluencerTier.NANO: 0.05,
                InfluencerTier.MICRO: 0.03,
                InfluencerTier.MID: 0.02,
                InfluencerTier.MACRO: 0.015,
                InfluencerTier.MEGA: 0.01,
            }
            est_engagements = profile.followers * default_rates.get(tier, 0.02)

        # åˆä½œæ•ˆç‡ = äº’åŠ¨æ•° / æŠ¥ä»·
        efficiency = est_engagements / max(1, est_rate)

        # NicheåŒ¹é…åŠ æˆ
        value_multiplier = 1.0 + (niche_score * 0.5)

        # ç»¼åˆä»·å€¼è¯„åˆ† (0-100)
        value_score = min(100, efficiency * value_multiplier * 50)

        return {
            "tier": tier.value,
            "estimated_rate_usd": round(est_rate, 0),
            "rate_range": rate_range,
            "estimated_cpe": round(est_cpe, 3),
            "estimated_engagements": round(est_engagements, 0),
            "efficiency": round(efficiency, 3),
            "niche_multiplier": round(value_multiplier, 2),
            "cooperation_value_score": round(value_score, 1),
        }


# â”€â”€ ç»¼åˆæ’åå™¨ â”€â”€


class InfluencerRanker:
    """å¤šç»´åŠ æƒç»¼åˆæ’å"""

    DEFAULT_WEIGHTS = {
        "niche": 0.30,
        "engagement_quality": 0.25,
        "growth": 0.20,
        "cooperation_value": 0.15,
        "authenticity": 0.10,
    }

    def __init__(self, weights: Optional[Dict[str, float]] = None):
        self.weights = weights or self.DEFAULT_WEIGHTS.copy()
        # å½’ä¸€åŒ–
        total = sum(self.weights.values())
        if total > 0:
            self.weights = {k: v / total for k, v in self.weights.items()}

    def rank(self, profiles: List[InfluencerProfile]) -> List[InfluencerProfile]:
        """æ ¹æ®overall_scoreæ’åº"""
        return sorted(profiles, key=lambda p: p.overall_score, reverse=True)

    def calculate_overall(
        self,
        niche_score: float,
        quality_score: float,
        growth_score: float,
        cooperation_score: float,
        authenticity_score: float = 0.5,
    ) -> float:
        """è®¡ç®—ç»¼åˆè¯„åˆ†"""
        scores = {
            "niche": niche_score,
            "engagement_quality": quality_score,
            "growth": growth_score,
            "cooperation_value": cooperation_score / 100,  # å½’ä¸€åŒ–åˆ°0-1
            "authenticity": authenticity_score,
        }
        total = sum(self.weights.get(k, 0) * v for k, v in scores.items())
        return round(min(1.0, max(0.0, total)), 3)


# â”€â”€ å…³æ³¨åˆ—è¡¨æŒä¹…åŒ– â”€â”€


class WatchList:
    """å½±å“è€…å…³æ³¨åˆ—è¡¨"""

    def __init__(self, db_path: str = "influencer_watchlist.db"):
        self.db_path = db_path
        self._local = threading.local()
        self._init_db()

    def _get_conn(self) -> sqlite3.Connection:
        if not hasattr(self._local, "conn") or self._local.conn is None:
            self._local.conn = sqlite3.connect(self.db_path)
            self._local.conn.row_factory = sqlite3.Row
            self._local.conn.execute("PRAGMA journal_mode=WAL")
        return self._local.conn

    def _init_db(self):
        conn = self._get_conn()
        conn.executescript("""
            CREATE TABLE IF NOT EXISTS watchlist (
                user_id TEXT PRIMARY KEY,
                username TEXT NOT NULL,
                display_name TEXT DEFAULT '',
                tier TEXT DEFAULT '',
                niche_score REAL DEFAULT 0,
                quality_score REAL DEFAULT 0,
                growth_score REAL DEFAULT 0,
                overall_score REAL DEFAULT 0,
                cooperation_value REAL DEFAULT 0,
                tags TEXT DEFAULT '[]',
                notes TEXT DEFAULT '',
                added_at TEXT NOT NULL DEFAULT (datetime('now')),
                updated_at TEXT NOT NULL DEFAULT (datetime('now')),
                status TEXT DEFAULT 'watching'
            );
            CREATE TABLE IF NOT EXISTS watchlist_events (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT NOT NULL,
                event_type TEXT NOT NULL,
                old_value TEXT,
                new_value TEXT,
                created_at TEXT NOT NULL DEFAULT (datetime('now')),
                FOREIGN KEY(user_id) REFERENCES watchlist(user_id)
            );
            CREATE INDEX IF NOT EXISTS idx_wl_status ON watchlist(status);
            CREATE INDEX IF NOT EXISTS idx_wl_score ON watchlist(overall_score DESC);
            CREATE INDEX IF NOT EXISTS idx_wle_user ON watchlist_events(user_id);
        """)
        conn.commit()

    def add(self, profile: InfluencerProfile, status: str = "watching") -> bool:
        """æ·»åŠ åˆ°å…³æ³¨åˆ—è¡¨"""
        conn = self._get_conn()
        now = datetime.now(timezone.utc).isoformat()
        try:
            conn.execute(
                """INSERT OR REPLACE INTO watchlist
                   (user_id, username, display_name, tier, niche_score, quality_score,
                    growth_score, overall_score, cooperation_value, tags, notes, added_at, updated_at, status)
                   VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?)""",
                (
                    profile.user_id, profile.username, profile.display_name,
                    profile.tier, profile.niche_score, profile.quality_score,
                    profile.growth_score, profile.overall_score, profile.cooperation_value,
                    json.dumps(profile.tags), profile.notes, now, now, status,
                ),
            )
            conn.execute(
                "INSERT INTO watchlist_events(user_id, event_type, new_value) VALUES(?,?,?)",
                (profile.user_id, "added", status),
            )
            conn.commit()
            return True
        except sqlite3.Error as e:
            logger.error("WatchList add failed: %s", e)
            return False

    def remove(self, user_id: str) -> bool:
        """ä»åˆ—è¡¨ç§»é™¤"""
        conn = self._get_conn()
        try:
            conn.execute("DELETE FROM watchlist WHERE user_id=?", (user_id,))
            conn.execute(
                "INSERT INTO watchlist_events(user_id, event_type) VALUES(?,?)",
                (user_id, "removed"),
            )
            conn.commit()
            return True
        except sqlite3.Error as e:
            logger.error("WatchList remove failed: %s", e)
            return False

    def get(self, user_id: str) -> Optional[Dict]:
        """è·å–å•ä¸ª"""
        conn = self._get_conn()
        row = conn.execute("SELECT * FROM watchlist WHERE user_id=?", (user_id,)).fetchone()
        return dict(row) if row else None

    def list_all(
        self,
        status: Optional[str] = None,
        min_score: float = 0.0,
        tier: Optional[str] = None,
        limit: int = 100,
    ) -> List[Dict]:
        """åˆ—å‡ºå…³æ³¨åˆ—è¡¨"""
        conn = self._get_conn()
        query = "SELECT * FROM watchlist WHERE overall_score >= ?"
        params: List = [min_score]
        if status:
            query += " AND status=?"
            params.append(status)
        if tier:
            query += " AND tier=?"
            params.append(tier)
        query += " ORDER BY overall_score DESC LIMIT ?"
        params.append(limit)
        rows = conn.execute(query, params).fetchall()
        return [dict(r) for r in rows]

    def update_scores(
        self,
        user_id: str,
        niche_score: Optional[float] = None,
        quality_score: Optional[float] = None,
        growth_score: Optional[float] = None,
        overall_score: Optional[float] = None,
    ) -> bool:
        """æ›´æ–°è¯„åˆ†"""
        conn = self._get_conn()
        sets = []
        params = []
        if niche_score is not None:
            sets.append("niche_score=?")
            params.append(niche_score)
        if quality_score is not None:
            sets.append("quality_score=?")
            params.append(quality_score)
        if growth_score is not None:
            sets.append("growth_score=?")
            params.append(growth_score)
        if overall_score is not None:
            sets.append("overall_score=?")
            params.append(overall_score)
        if not sets:
            return False
        sets.append("updated_at=?")
        params.append(datetime.now(timezone.utc).isoformat())
        params.append(user_id)
        try:
            conn.execute(f"UPDATE watchlist SET {', '.join(sets)} WHERE user_id=?", params)
            conn.commit()
            return True
        except sqlite3.Error as e:
            logger.error("WatchList update failed: %s", e)
            return False

    def get_events(self, user_id: str, limit: int = 50) -> List[Dict]:
        """è·å–å˜åŠ¨äº‹ä»¶"""
        conn = self._get_conn()
        rows = conn.execute(
            "SELECT * FROM watchlist_events WHERE user_id=? ORDER BY created_at DESC LIMIT ?",
            (user_id, limit),
        ).fetchall()
        return [dict(r) for r in rows]

    def stats(self) -> Dict:
        """ç»Ÿè®¡æ¦‚è§ˆ"""
        conn = self._get_conn()
        total = conn.execute("SELECT COUNT(*) FROM watchlist").fetchone()[0]
        by_tier = {}
        for row in conn.execute("SELECT tier, COUNT(*) as cnt FROM watchlist GROUP BY tier").fetchall():
            by_tier[row["tier"]] = row["cnt"]
        by_status = {}
        for row in conn.execute("SELECT status, COUNT(*) as cnt FROM watchlist GROUP BY status").fetchall():
            by_status[row["status"]] = row["cnt"]
        avg_score_row = conn.execute("SELECT AVG(overall_score) FROM watchlist").fetchone()
        avg_score = avg_score_row[0] if avg_score_row[0] else 0.0
        return {
            "total": total,
            "by_tier": by_tier,
            "by_status": by_status,
            "avg_overall_score": round(avg_score, 3),
        }


# â”€â”€ ç»„åˆæ¥å£ â”€â”€


class InfluencerFinder:
    """å½±å“è€…å‘ç°å¼•æ“ â€” ç»Ÿä¸€å…¥å£"""

    def __init__(
        self,
        niche: Optional[NicheConfig] = None,
        db_dir: str = ".",
        weights: Optional[Dict[str, float]] = None,
    ):
        self.niche = niche or NicheConfig(name="general")
        self.scorer = NicheScorer(self.niche)
        self.quality_analyzer = EngagementQualityAnalyzer()
        self.growth_tracker = GrowthTracker(f"{db_dir}/influencer_growth.db")
        self.cooperation = CooperationEstimator()
        self.ranker = InfluencerRanker(weights)
        self.watchlist = WatchList(f"{db_dir}/influencer_watchlist.db")

    def evaluate(
        self,
        profile: InfluencerProfile,
        tweets: Optional[List[Dict]] = None,
        samples: Optional[List[EngagementSample]] = None,
    ) -> InfluencerProfile:
        """å®Œæ•´è¯„ä¼°ä¸€ä¸ªå½±å“è€…"""
        # 1. Tier
        profile.tier = InfluencerTier.from_followers(profile.followers).value

        # 2. Nicheè¯„åˆ†
        profile.niche_score = self.scorer.score(profile, tweets or [])

        # 3. äº’åŠ¨è´¨é‡
        quality = self.quality_analyzer.analyze(samples or [])
        profile.quality_score = quality["quality_score"]

        # 4. å¢é•¿è¯„åˆ†
        self.growth_tracker.record(
            profile.user_id, profile.followers, profile.following, profile.tweet_count
        )
        profile.growth_score = self.growth_tracker.growth_score(profile.user_id)

        # 5. åˆä½œä»·å€¼
        avg_eng = 0.0
        if samples:
            avg_eng = sum(s.total_engagement for s in samples) / len(samples)
        coop = self.cooperation.estimate(profile, avg_eng, profile.niche_score)
        profile.cooperation_value = coop["cooperation_value_score"]

        # 6. ç»¼åˆè¯„åˆ†
        profile.overall_score = self.ranker.calculate_overall(
            profile.niche_score,
            profile.quality_score,
            profile.growth_score,
            profile.cooperation_value,
        )

        # æ—¶é—´æˆ³
        now = datetime.now(timezone.utc).isoformat()
        if not profile.discovered_at:
            profile.discovered_at = now
        profile.last_updated = now

        return profile

    def batch_evaluate(
        self,
        profiles: List[InfluencerProfile],
        tweets_map: Optional[Dict[str, List[Dict]]] = None,
        samples_map: Optional[Dict[str, List[EngagementSample]]] = None,
    ) -> List[InfluencerProfile]:
        """æ‰¹é‡è¯„ä¼° + æ’å"""
        tweets_map = tweets_map or {}
        samples_map = samples_map or {}
        results = []
        for p in profiles:
            tweets = tweets_map.get(p.user_id, [])
            samples = samples_map.get(p.user_id, [])
            results.append(self.evaluate(p, tweets, samples))
        return self.ranker.rank(results)

    def discover_from_seed(self, seed_usernames: List[str]) -> List[str]:
        """ä»ç§å­è´¦å·å‘ç°æ›´å¤šå€™é€‰(è¿”å›ç”¨æˆ·ååˆ—è¡¨ä¾›APIæŠ“å–)"""
        # ç­–ç•¥: ç§å­è´¦å·çš„äº’åŠ¨è€… / å…³æ³¨è€…äº¤é›†
        candidates: Set[str] = set()
        for u in seed_usernames:
            candidates.add(u)
        # çœŸå®å®ç°éœ€è¦APIè°ƒç”¨ï¼Œè¿™é‡Œè¿”å›ç§å­åˆ—è¡¨
        return list(candidates)

    def export_report(self, profiles: List[InfluencerProfile], format: str = "json") -> str:
        """å¯¼å‡ºè¯„ä¼°æŠ¥å‘Š"""
        if format == "json":
            return json.dumps([p.to_dict() for p in profiles], indent=2, default=str)
        elif format == "csv":
            lines = ["username,tier,niche,quality,growth,cooperation,overall"]
            for p in profiles:
                lines.append(
                    f"{p.username},{p.tier},{p.niche_score:.3f},{p.quality_score:.3f},"
                    f"{p.growth_score:.3f},{p.cooperation_value:.1f},{p.overall_score:.3f}"
                )
            return "\n".join(lines)
        elif format == "text":
            lines = [f"ğŸ” Influencer Report ({len(profiles)} profiles)", "=" * 50]
            for i, p in enumerate(profiles, 1):
                lines.append(
                    f"#{i} @{p.username} [{p.tier}] "
                    f"Score:{p.overall_score:.3f} | "
                    f"Niche:{p.niche_score:.2f} Quality:{p.quality_score:.2f} "
                    f"Growth:{p.growth_score:.2f}"
                )
            return "\n".join(lines)
        return ""
